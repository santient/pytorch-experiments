{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(api_key=\"E3oWJUSFulpXpCUQfc5oGz0zY\", project_name=\"pytorch-vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "latent_dim = 128\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = img_size // 2**4\n",
    "h_dim = 256*ds_size**2\n",
    "h_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal(object):\n",
    "    def __init__(self, mu, sigma, log_sigma, v=None, r=None):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma  # either stdev diagonal itself, or stdev diagonal from decomposition\n",
    "        self.logsigma = log_sigma\n",
    "        dim = mu.get_shape()\n",
    "        if v is None:\n",
    "            v = Tensor(*dim)\n",
    "        if r is None:\n",
    "            r = Tensor(*dim)\n",
    "        self.v = v\n",
    "        self.r = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, 3, 1, 1),\n",
    "            nn.Conv2d(32, 32, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(256, 0.8)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 2**4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 256*self.init_size**2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),\n",
    "            nn.Conv2d(32, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self._enc_mu = nn.Linear(h_dim, latent_dim)\n",
    "        self._enc_log_sigma = nn.Linear(h_dim, latent_dim)\n",
    "\n",
    "    def _sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        mu = self._enc_mu(h_enc)\n",
    "        log_sigma = self._enc_log_sigma(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = Variable(Tensor(np.random.normal(0, 1, size=sigma.size())))\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_sigma = sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
    "\n",
    "    def forward(self, state):\n",
    "        h_enc = self.encoder(state)\n",
    "        z = self._sample_latent(h_enc)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(z_mean, z_stddev):\n",
    "    mean_sq = z_mean * z_mean\n",
    "    stddev_sq = z_stddev * z_stddev\n",
    "    return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().cuda()\n",
    "decoder = Decoder().cuda()\n",
    "vae = VAE(encoder, decoder).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder)\n",
    "print(decoder)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "vae.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"/home/santiago/Downloads/celebA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "workers = 4\n",
    "dataset = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.CenterCrop(128),\n",
    "                               transforms.Resize(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples: ', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../images\", exist_ok=True)\n",
    "os.makedirs(\"../checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "sample_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with experiment.train():\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs = Variable(data[0].type(Tensor))\n",
    "            optimizer.zero_grad()\n",
    "            dec = vae(inputs)\n",
    "            ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "            loss = criterion(dec, inputs) + ll\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l = loss.data[0]\n",
    "            batches_done += 1\n",
    "            experiment.log_metric(\"loss\", l, step=batches_done)\n",
    "            if batches_done % sample_interval == 0:\n",
    "                save_image(dec.data[:25], \"../images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "                torch.save(encoder.state_dict(), '../checkpoints/encoder_%d.pth' % batches_done)\n",
    "                torch.save(decoder.state_dict(), '../checkpoints/decoder_%d.pth' % batches_done)\n",
    "                torch.save(vae.state_dict(), '../checkpoints/vae_%d.pth' % batches_done)\n",
    "                torch.save(optimizer.state_dict(), '../checkpoints/optimizer_%d.pth' % batches_done)\n",
    "            print(\"epoch: {}/{}, step: {}/{}, global_step: {}, loss: {}\".format(epoch, n_epochs, i, len(dataloader), batches_done, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(dec.data[:25], \"../images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "torch.save(encoder.state_dict(), '../checkpoints/encoder_%d.pth' % batches_done)\n",
    "torch.save(decoder.state_dict(), '../checkpoints/decoder_%d.pth' % batches_done)\n",
    "torch.save(vae.state_dict(), '../checkpoints/vae_%d.pth' % batches_done)\n",
    "torch.save(optimizer.state_dict(), '../checkpoints/optimizer_%d.pth' % batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (inputs.shape[0], latent_dim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(test.data[:25], \"../images/test.png\", nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
